---
layout: post
title: AI를 적용하기 좋은 주제에 관하여
date: 2024-06-15 10:00:00
description: 인공지능을 효과적으로 적용하기 위한 데이터셋 구축 및 선정 가이드
tags: AI machine-learning data-science korean
categories: AI
---

AI를 적용하기 좋은 주제는 주로 양질의 학습 데이터가 제공되는 경우이다.

### 1000개 이상의 데이터포인트를 확보하자

(보통 인공지능 모델을 학습하는데 있어서) 데이터포인트가 최소 1000개 이상이 필요하다. 생각보다 적은 인원으로 데이터를 수작업으로 만들 수 있는 경우도 존재한다.

예를 들어, (물론 이미 인터넷 상에 공개되어 있는 데이터셋이지만) 얼굴 인식 데이터셋을 직접 만들고 싶다면 사람의 얼굴이 있는 부분을 색칠하면 된다. 인원이 3명이면, 한 사람당 이미지 333개에서 얼굴을 색칠하는 노가다 작업을 하면 학습을 시작할 수 있다.

### 데이터 얻기 1 | 공개된 데이터셋의 활용

물론 시간을 절약하는 가장 좋은 방법은 이미 공개되어 있는 데이터셋을 활용하는 것이다. 공개된 데이터셋은 (분야 이름) + dataset으로 검색하면 잘 나오고, 이미 선행 연구에서 사용 중인 표준 데이터셋이 존재한다면 이를 활용하는 것이 일반적이다. 표준 데이터셋을 활용할 경우 객관적인 성능 비교가 가능하다는 측면에서 장점이 있다.

### 데이터 얻기 2 | 직접 데이터셋을 구축하는 방법

하지만, 우리가 해결하려는 문제를 대변하는 좋은 데이터셋이 없다면 직접 구축하는 수밖에 없다. 귀찮은 작업이더라도, 새로운 분야에 인공지능을 접목하는 연구에서는 필수적인 작업이다. 오히려, 데이터셋을 구축하여 오픈소스로 공개한 뒤 해당 데이터셋이 분야 표준으로 자리잡는다면, 연구의 기여를 인정받을 수 있다.

### 데이터 얻기 3 | 기업체 또는 아르바이트를 활용하여 아웃소싱

돈이 충분하다면, 학습 데이터셋을 구축하는 작업을 외주로 맡길 수 있다. 데이터 레이블링(지도학습 데이터셋 구축)을 전문으로 하는 회사들이 있다. 또는, 데이터레이블링을 단기 알바 형태로 만들어 크라우드소싱(crowdsourcing)을 통해 해결하는 경우도 있다.

### 학습할 수 있는 데이터에는 어떤 것이 있는가?

반드시 숫자로 표현할 수 있는 데이터가 아니어도 괜찮다. 영어, 한국어 등 사람이 평소에 사용하는 언어인 자연어(natural language)로 표현된 데이터, 이미지/동영상 데이터 등 디지털화할 수 있는 정보는 대부분 학습 가능하다.

그러나, 디지털화가 제대로 진행되지 않은 정보의 처리를 요구하는 경우 학습 데이터 구축에 난항을 겪을 수 있다. 예를 들어, 아직 그 어느 기관에서도 설문조사를 통해 질의한 적이 없는 질문에 대한 답변을 학습시키고 싶다면, 데이터셋을 구축하는 것만으로도 수개월이 걸릴 수 있다.

또는, 데이터 생성에 필요한 센서가 대중화되어 있지 않은 경우 제공 받을 수 있는 학습 데이터의 양에 근본적인 제약이 걸릴 수 있다. 예를 들어, 음식을 맛보는 센서는 지금까지 스마트폰에 탑재되었던 적이 없었기 때문에, 학습 데이터를 얻으려면 음식의 구성 성분을 분석할 수 있는 전문 실험 장비를 보유한 회사/연구소에 의뢰하여야 한다.

### 학습 데이터의 대표성

데이터 수집 과정에서 편향이 발생하지는 않았는지 충분히 살펴보아야 한다. 당연한 이야기이지만, 서울 시민을 표본으로 한 여론 조사 데이터셋을 학습한 인공지능이 대한민국에서 선출될 대통령을 예상할 수는 없다.

데이터셋을 만드는 사람은 일관되고 정확한 방식으로 데이터셋을 생성해야 한다. 기계학습에서의 목적은 데이터의 종합적인 경향성과 패턴을 파악하는 것이기에 어느 정도의 실수는 용인되지만, 실수가 너무 잦거나 아웃라이어(outlier)에 해당하는 극단적인 샘플이 섞여들어갈 경우 학습이 제대로 진행되지 않을 수 있다.

또한 너무 오래된 데이터셋을 활용하면 예측 정확도가 떨어질 수 있다. 예를 들어, 1900년대 주식 데이터셋만 가지고 있을 경우, 2000년대가 되어서야 대중화된 디지털 기기의 존재를 알 수 없기 때문에 이것으로 트레이딩 자동화를 시도하겠다는 것은 터무니없는 이야기라고 할 수 있겠다.

반대로, 전쟁과 같이 비교적 큰 타임스케일(time-scale)로 발생하는 사건을 예측하는 인공지능을 만들고자 할 때, 2000년대 이후의 최신 데이터만을 이용해서 학습하는 것은 적절하지 못할 것이다. 충분히 많은 전쟁에 대한 정보가 누적되어야 하는데 2000년부터 지금까지 대규모 전쟁이 발발한 적은 없기 때문이다.

학습 데이터가 시뮬레이션을 통해 얻어질 경우, 해당 시뮬레이션이 충분히 믿을만한 결과를 제공하는지에 대해 엄밀하게 분석해보아야 한다. 예를 들어, 학습 데이터를 경제 시뮬레이션을 통해 생성했는데, 해당 시뮬레이션이 현실을 제대로 대변하지 못한다면, 학습이 되더라도 학습의 결과가 시뮬레이션 상에서만 만족스럽고 정작 현실 상황에 적용 불가능할 수 있다. 이를 심-투-리얼 갭(sim-to-real gap)이라고 한다.